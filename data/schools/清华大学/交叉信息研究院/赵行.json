{
    "html": "<!DOCTYPE html><html lang=\"zh-cn\" style=\"font-size: 67px;\"><head>\n<title>赵行-交叉信息研究院</title><meta name=\"keywords\" content=\"交叉信息研究院,赵行\">\n\n<meta charset=\"utf-8\">\n<meta name=\"renderer\" content=\"webkit\">\n\n<meta name=\"description\" content=\"\">\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\">\n<meta name=\"format-detection\" content=\"telephone=no,email=no,adress=no,date=no\">\n<link rel=\"apple-touch-icon-precomposed\" href=\"../../images/favicon.png\">\n<link rel=\"icon\" sizes=\"72*72\" href=\"../../images/favicon.png\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../../css/public.css\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../../css/body.css\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../../css/ny.css\">\n<script type=\"text/javascript\" src=\"../../js/jq.js\"></script>\n<!--[if lte IE 9]>\n  <script type=\"text/javascript\" src=\"../../js/jquery.js\"></script>\n<![endif]-->\n<script src=\"../../js/script.js\"></script>\n<!--Announced by Visual SiteBuilder 9-->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../../_sitegray/_sitegray_d.css\">\n<script language=\"javascript\" src=\"../../_sitegray/_sitegray.js\"></script>\n<!-- CustomerNO:77656262657232307e78475c5356574200000003435c -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../../rydw-dp-xgyjgz.vsb.css\">\n<script type=\"text/javascript\" src=\"/system/resource/js/counter.js\"></script>\n<script type=\"text/javascript\">_jsq_(1079,'/rydw-dp-xgyjgz.jsp',-1,2110873241)</script>\n</head>\n<body data-aos-easing=\"ease\" data-aos-duration=\"1200\" data-aos-delay=\"0\">\n<div id=\"load\" style=\"display: none;\"></div>\n\n<div id=\"app\">\n    \n    <header class=\"header\">\n        <div class=\"wp flexjs\">\n          <div class=\"logo\">\n            \n\n\n\n\n\n\n\n<script language=\"javascript\" src=\"/system/resource/js/dynclicks.js\"></script><script language=\"javascript\" src=\"/system/resource/js/centerCutImg.js\"></script><p>\n</p>\n\n            \n            <div class=\"a\">\n                  <a href=\"../../index.htm\" onclick=\"_addDynClicks(&quot;wbimage&quot;, 2110873241, 1019076)\"><img src=\"../../images/logo.png\" border=\"0\" class=\"i1\"></a>\n\n              \n<!-- 网站logo图片地址请在本组件\"内容配置-网站logo\"处填写 -->\n<a href=\"../../index.htm\" title=\"交叉信息研究院主页\"><img src=\"../../images/logos.png\" alt=\"\" class=\"i2\"></a>\n            </div>\n          </div>\n\n          <div class=\"topr flexjs flexc\">\n            <div class=\"toplink flex\">\n              <ul class=\"flex\">\n                <li>    \n<a href=\"javascript:;\" class=\"a\" onclick=\"_addDynClicks(&quot;wbimage&quot;, 2110873241, 1019079)\"><i class=\"swi-weixin0\"></i>微信公众号</a>\n                  <div class=\"ewm\">\n                    <img src=\"../../images/ewm.png\" border=\"0\">\n                  </div>\n                \n\n</li>\n                <script language=\"javascript\" src=\"/system/resource/js/openlink.js\"></script>\n<li>\n                  <a href=\"http://cqi.tsinghua.edu.cn/\" title=\"\" onclick=\"_addDynClicks(&quot;wburl&quot;, 2110873241, 108887)\" class=\"a\"><i class=\"swi-shouye\"></i>CQI官网</a>\n                </li>\n    \n\n\n                \n                <li><a href=\"https://iiis.tsinghua.edu.cn/en/People/Faculty/ZhaoHang.htm\" class=\"a\">EN</a></li>\n                <li>\n                  <a href=\"javascript:;\" class=\"showSear swi-search-outlined\"></a>\n                </li>\n              </ul>\n            </div>\n            <div class=\"topnav flex\">\n              <ul class=\"flex\">   <li><a href=\"../../index.htm\">首页</a></li>\n   \n\n                <li>\n                  <a href=\"../../yxgk/yxjj.htm\">院系概况</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../yxgk/yxjj.htm\">院系简介</a>\n                      \n                      <a href=\"../../yxgk/yzjy.htm\">院长寄语</a>\n                      \n                      <a href=\"../../yxgk/xrld.htm\">现任领导</a>\n                      \n                      <a href=\"../../yxgk/yxyg.htm\">院系沿革</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../xwdt/yxdt.htm\">新闻动态</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../xwdt/yxdt.htm\">院系动态</a>\n                      \n                      <a href=\"../../xwdt/mtjj.htm\">媒体聚焦</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../rydw.htm\">人员队伍</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../rydw.htm#sz1\" class=\"at\">全职教师</a>\n                      \n                      <a href=\"../../rydw.htm#sz8\">研究系列</a>\n                      \n                      <a href=\"../../rydw.htm#sz2\">荣誉客座</a>\n                      \n                      <a href=\"../../rydw.htm#sz3\">兼职教师</a>\n                      \n                      <a href=\"../../rydw.htm#sz4\">博士后</a>\n                      \n                      <a href=\"../../rydw.htm#sz5\">行政人员</a>\n                      \n                      <a href=\"../../rydw.htm#sz6\">实验员</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../ybbks/ybpy.htm\">姚班本科生</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../ybbks/ybpy.htm\">姚班培养</a>\n                      \n                      <a href=\"../../ybbks/ybzs.htm\">姚班招生</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../yjs/yjspy.htm\">研究生</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../yjs/yjspy.htm\">研究生培养</a>\n                      \n                      <a href=\"../../yjs/yjszs.htm\">研究生招生</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../lzzx/zxjj.htm\">量子中心</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../lzzx/zxjj.htm\">中心简介</a>\n                      \n                      <a href=\"../../lzzx/zxjj.htm#lzsz\">师资力量</a>\n                      \n                      <a href=\"../../lzzx/kygk.htm\">科研概况</a>\n                      \n                      <a href=\"../../lzzx/lzzxdt.htm\">量子中心动态</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../kxyj/zzjg.htm\">科学研究</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../kxyj/zzjg.htm\">组织架构</a>\n                      \n                      <a href=\"../../kxyj/ktzjs.htm\">课题组介绍</a>\n                      \n                      <a href=\"../../kxyj/yjdt.htm\">研究动态</a>\n                      \n                      <a href=\"../../kxyj/kyjb.htm\">科研简报</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../xysh/xshd/nljlb.htm\">校园生活</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../xysh/xshd/nljlb.htm\">学生活动</a>\n                      \n                      <a href=\"../../xysh/yszx.htm\">衣食住行</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../gkzp.htm\">公开招聘</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../gkzp/jszp.htm\">教师招聘</a>\n                      \n                      <a href=\"../../gkzp/bshzp.htm\">博士后招聘</a>\n                      \n                      <a href=\"../../gkzp/zyzp.htm\">职员招聘</a>\n                    </div>\n                  </div>\n                </li>\n\n                <li>\n                  <a href=\"../../xypd/xyfc.htm\">校友频道</a>\n                  <i class=\"plus swi-down-outlined\"></i>\n                  <div class=\"sub-nav\">\n                    <div class=\"sub-nav-h\">\n                      \n                      <a href=\"../../xypd/xyfc.htm\">校友风采</a>\n                      \n                      <a href=\"../../xypd/xyjlb/zqjlb.htm\">校友俱乐部</a>\n                      \n                      <a href=\"../../xypd/xyjz.htm\">校友捐赠</a>\n                    </div>\n                  </div>\n                </li>\n\n\n                \n                \n</ul>\n\n              <div id=\"openBtn\" class=\"btn rd-navbar-toggle\">\n                <div class=\"lcbody\">\n                  <div class=\"lcitem top\">\n                    <div class=\"rect top\"></div>\n                  </div>\n                  <div class=\"lcitem center hide\">\n                    <div class=\"rect bottom\"></div>\n                  </div>\n                  <div class=\"lcitem bottom\">\n                    <div class=\"rect bottom\"></div>\n                  </div>\n                </div>\n              </div>\n            </div>\n\n            <form action=\"\" class=\"miso_form1\">\n              <div class=\"input-group pore\">\n                <input type=\"text\" name=\"showkeycode\" id=\"\" class=\"inp\" placeholder=\"\" autocomplete=\"off\">\n                <button class=\"sub\" type=\"submit\"></button>\n              </div>\n            </form>\n          </div>\n\n          <div class=\"navBtnm flex\">\n            <a href=\"javascript:;\" class=\"navbtn\">\n              <button class=\"menu-btn\">\n                <span class=\"line-1\"></span>\n                <span class=\"line-2\"></span>\n                <span class=\"line-3\"></span>\n              </button>\n            </a>\n          </div>\n        </div>\n      </header>\n\n     <div class=\"site-menu\" data-lenis-prevent=\"\">\n        <div class=\"site-menu-main px-container\">\n            <div class=\"bottom\">\n                <div class=\"wp\">\n                    <div class=\"hd\">\n                        <ul class=\"ul flex\">\n                                                       <li>\n                                <a href=\"../../index.htm\">首页</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../index/rdxw.htm\">热点新闻</a>\n                                       \n                      <a href=\"../../index/jzyg.htm\">讲座预告</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../yxgk/yxjj.htm\">院系概况</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../yxgk/yxjj.htm\">院系简介</a>\n                                       \n                      <a href=\"../../yxgk/yzjy.htm\">院长寄语</a>\n                                       \n                      <a href=\"../../yxgk/xrld.htm\">现任领导</a>\n                                       \n                      <a href=\"../../yxgk/yxyg.htm\">院系沿革</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../xwdt/yxdt.htm\">新闻动态</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../xwdt/yxdt.htm\">院系动态</a>\n                                       \n                      <a href=\"../../xwdt/mtjj.htm\">媒体聚焦</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../rydw.htm\">人员队伍</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../rydw.htm#sz1\">全职教师</a>\n                                       \n                      <a href=\"../../rydw.htm#sz8\">研究系列</a>\n                                       \n                      <a href=\"../../rydw.htm#sz2\">荣誉客座</a>\n                                       \n                      <a href=\"../../rydw.htm#sz3\">兼职教师</a>\n                                       \n                      <a href=\"../../rydw.htm#sz4\">博士后</a>\n                                       \n                      <a href=\"../../rydw.htm#sz5\">行政人员</a>\n                                       \n                      <a href=\"../../rydw.htm#sz6\">实验员</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../ybbks/ybpy.htm\">姚班本科生</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../ybbks/ybpy.htm\">姚班培养</a>\n                                       \n                      <a href=\"../../ybbks/ybzs.htm\">姚班招生</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../yjs/yjspy.htm\">研究生</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../yjs/yjspy.htm\">研究生培养</a>\n                                       \n                      <a href=\"../../yjs/yjszs.htm\">研究生招生</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../lzzx/zxjj.htm\">量子中心</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../lzzx/zxjj.htm\">中心简介</a>\n                                       \n                      <a href=\"../../lzzx/zxjj.htm#lzsz\">师资力量</a>\n                                       \n                      <a href=\"../../lzzx/kygk.htm\">科研概况</a>\n                                       \n                      <a href=\"../../lzzx/lzzxdt.htm\">量子中心动态</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../kxyj/zzjg.htm\">科学研究</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../kxyj/zzjg.htm\">组织架构</a>\n                                       \n                      <a href=\"../../kxyj/ktzjs.htm\">课题组介绍</a>\n                                       \n                      <a href=\"../../kxyj/yjdt.htm\">研究动态</a>\n                                       \n                      <a href=\"../../kxyj/kyjb.htm\">科研简报</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../xysh/xshd/nljlb.htm\">校园生活</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../xysh/xshd/nljlb.htm\">学生活动</a>\n                                       \n                      <a href=\"../../xysh/yszx.htm\">衣食住行</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../gkzp.htm\">公开招聘</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../gkzp/jszp.htm\">教师招聘</a>\n                                       \n                      <a href=\"../../gkzp/bshzp.htm\">博士后招聘</a>\n                                       \n                      <a href=\"../../gkzp/zyzp.htm\">职员招聘</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n                            <li>\n                                <a href=\"../../xypd/xyfc.htm\">校友频道</a>\n                                <div class=\"sub-nav\">\n                                    <div class=\"sub-nav-h\">\n                      <a href=\"../../xypd/xyfc.htm\">校友风采</a>\n                                       \n                      <a href=\"../../xypd/xyjlb/zqjlb.htm\">校友俱乐部</a>\n                                       \n                      <a href=\"../../xypd/xyjz.htm\">校友捐赠</a>\n                                       \n                                    </div>\n                                </div>\n                            </li>\n                            \n\n\n</ul>\n</div>\n                </div>\n            </div>\n        </div>\n      </div>\n\n  <div class=\"n_container n_b1 rydw_d\">\n  <div id=\"waveContainer\"><canvas width=\"1280\" height=\"360\" style=\"width: 1280px; height: 360px;\"></canvas></div>\n    <div class=\"wp\">\n      <div class=\"n_yj\"><h4>\n\n\n\n<font>人员队伍</font></h4></div>\n      <div class=\"n_ej\">\n        <ul class=\"flex\">\n          \n    <li class=\"on\"><a href=\"../../rydw.htm#sz1\" class=\"a\">全职教师</a></li>\n           \n    <li><a href=\"../../rydw.htm#sz8\" class=\"a\">研究系列</a></li>\n           \n    <li><a href=\"../../rydw.htm#sz2\" class=\"a\">荣誉客座</a></li>\n           \n    <li><a href=\"../../rydw.htm#sz3\" class=\"a\">兼职教师</a></li>\n           \n    <li><a href=\"../../rydw.htm#sz4\" class=\"a\">博士后</a></li>\n           \n    <li><a href=\"../../rydw.htm#sz5\" class=\"a\">行政人员</a></li>\n           \n    <li><a href=\"../../rydw.htm#sz6\" class=\"a\">实验员</a></li>\n           \n</ul>\n\n      </div>\n    </div>\n    <div class=\"fl1 n_pad1\">\n      <div class=\"wp flexjs\">\n        <div class=\"left\">\n          <div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<script language=\"javascript\" src=\"/system/resource/js/ajax.js\"></script><script language=\"javascript\">_getBatchClickTimes('null',2110873241,'wbnews','u10')</script>\n<script>function seeContenta10(contentid,size,displayid){    document.getElementById(contentid).innerHTML = '[';    for(var i=0;i<=size;i++){        var allcontentid = contentid+(i+1);        if(allcontentid==displayid){            document.getElementById(contentid).innerHTML += \" <span id='\"+allcontentid+\"' name='\"+allcontentid+\"'  >\"+(i+1)+\"</span> \";            document.getElementById(displayid).style.display = 'block';        }else{            document.getElementById(contentid).innerHTML += \" <span style='cursor:pointer' id='\"+allcontentid+\"' name='\"+allcontentid+\"' onclick=seeContenta10('\"+contentid+\"','\"+size+\"','\"+allcontentid+\"')  >\"+(i+1)+\"</span> \";            document.getElementById(allcontentid).style.display = 'none';        }    }    document.getElementById(contentid).innerHTML += ']';}</script>\n<script language=\"javascript\" src=\"/system/resource/js/news/mp4video.js\"></script>\n<script>_addDynClicks('wbnews',2110873241,3657)</script>\n\n<div class=\"box box0 box1 flex\">\n            <div class=\"imgBox trans\">\n              <div class=\"img light\">\n                <img src=\"../../zpyx/zhaohang.jpg\" alt=\"\">\n              </div>\n            </div>\n            <div class=\"con con1\">\n              <h3>赵行</h3>\n              <h6></h6>\n              <p>助理教授</p>\n              <p>计算机视觉，多模态机器学习，自动驾驶，机器人学习</p>\n            </div>\n          </div>\n\n    <div class=\"box box0 box2 aos-init aos-animate\" data-aos=\"fade-up\">\n       \n         <h3 class=\"h3-5 flex\"></h3>\n                <div class=\"arc-con arc-cons1\"><div class=\"v_news_content\">\n<div>\n <p class=\"vsbcontent_start\">Hey, I am Hang Zhao, an Assistant Professor at IIIS, Tsinghua University, Principle Investigator of <a href=\"http://group.iiis.tsinghua.edu.cn/~marslab/\">MARS Lab</a>. My research interests are <b>multi-modal machine learning, autonomous driving and robot learning</b>. Check out our <a href=\"http://group.iiis.tsinghua.edu.cn/~marslab/\"><b>MARS Lab Website</b></a> for a full list of research projects and publications.</p>\n <p>I was a Research Scientist at <a href=\"https://waymo.com/\">Waymo</a> (known as Google's self-driving project) from 2019 to 2020. Before that, I got my Ph.D. degree at <a href=\"http://www.mit.edu/\">MIT</a> in 2019 under the supervision of Professor <a href=\"http://web.mit.edu/torralba/www/\">Antonio Torralba</a> (the Great Torralba!). Before MIT, I received my B.S. from Zhejiang University in 2013.</p>\n <p class=\"vsbcontent_end\"><b>I am actively looking for PostDoc/PhD/BS students and engineers with CS/EE background to join my team. If you would like to work with me, feel free to drop me an email with your resume.</b></p>\n <h2></h2>\n</div>\n</div></div>\n \n  </div>\n  \n    <div class=\"box box0 box3 aos-init\" data-aos=\"fade-up\">\n       \n         <h3 class=\"h3-5 flex\"><img src=\"../../images/h3-5.png\" alt=\"\">Selected Projects</h3>\n                <div class=\"arc-con arc-cons1\"><h2></h2>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"159\" src=\"/__local/3/E7/5A/FDB064C1DD1B4A02806E4E08302_847D5E9E_33D8E.png\" vsbhref=\"vurl\" vurl=\"/_vsl/3E75AFDB064C1DD1B4A02806E4E08302/847D5E9E/33D8E\" vheight=\"159\" vwidth=\"333\" orisrc=\"/__local/3/E7/5A/FDB064C1DD1B4A02806E4E08302_847D5E9E_33D8E.png\" class=\"img_vsb_content\"></p>\n<p><b>Humanoid Parkour Learning</b> Hot</p>\n<p>Ziwen Zhuang, Shenzhe Yao, Hang Zhao</p>\n<p>CoRL 2024</p>\n<p><i>\"The first humanoid robot that learns to parkour!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2406.10759\">Paper</a> <a href=\"https://humanoid4parkour.github.io/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"189\" src=\"/__local/A/96/B8/BF6E7BCC2F5697138A5614C4E33_E7099961_3DA05.png\" vsbhref=\"vurl\" vurl=\"/_vsl/A96B8BF6E7BCC2F5697138A5614C4E33/E7099961/3DA05\" vheight=\"189\" vwidth=\"333\" orisrc=\"/__local/A/96/B8/BF6E7BCC2F5697138A5614C4E33_E7099961_3DA05.png\" class=\"img_vsb_content\"></p>\n<p><b>DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models</b> Hot</p>\n<p>Xiaoyu Tian, Junru Gu, Bailin Li, Yicheng Liu, Yang Wang, Zhiyong Zhao, Kun Zhan</p>\n<p>Peng Jia, Xianpeng Lang, Hang Zhao</p>\n<p>CoRL 2024</p>\n<p><i>\"Slow-Fast Dual System for autnomous driving!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2402.12289\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/DriveVLM/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"250\" src=\"/__local/8/75/28/2D9E79B5D02BC3A8948D91A270E_2A98BA51_5182D.png\" vsbhref=\"vurl\" vurl=\"/_vsl/875282D9E79B5D02BC3A8948D91A270E/2A98BA51/5182D\" vheight=\"250\" vwidth=\"333\" orisrc=\"/__local/8/75/28/2D9E79B5D02BC3A8948D91A270E_2A98BA51_5182D.png\" class=\"img_vsb_content\"></p>\n<p><b>Latent Consistency Models: Synthesizing High-Resolution Images With Few-Step Inference</b> Hot</p>\n<p>Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, Hang Zhao</p>\n<p><i>\"Generating high-resolution images in only 2-4 steps!\"</i></p>\n<p><b>LCM-LoRA: A Universal Stable-Diffusion Acceleration Module</b></p>\n<p>Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von Platen, Apolinário Passos,</p>\n<p>Longbo Huang, Jian Li, Hang Zhao</p>\n<p><i>\"Accelerating your LoRA model by 5x without training!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2310.04378\">LCM Paper</a> <a href=\"https://arxiv.org/abs/2311.05556\">LCM-LoRA Report</a> <a href=\"https://huggingface.co/spaces/SimianLuo/Latent_Consistency_Model\">Demo</a> <a href=\"https://latent-consistency-models.github.io/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"204\" src=\"/__local/A/71/6D/CF500356919BDE92306337EC82A_514CF177_42849.png\" vsbhref=\"vurl\" vurl=\"/_vsl/A716DCF500356919BDE92306337EC82A/514CF177/42849\" vheight=\"204\" vwidth=\"333\" orisrc=\"/__local/A/71/6D/CF500356919BDE92306337EC82A_514CF177_42849.png\" class=\"img_vsb_content\"></p>\n<p><b>Robot Parkour Learning</b> Hot</p>\n<p>Ziwen Zhuang, Zipeng Fu, Jianren Wang, Christopher G Atkeson, Sören Schwertfeger,</p>\n<p>Chelsea Finn, Hang Zhao</p>\n<p><b>CoRL 2023 Oral Best System Paper Finalist (Top 3)</b></p>\n<p><i>\"Robot parkour skills empowered by onboard vision and a neural network!\"</i></p>\n<p><a href=\"https://robot-parkour.github.io/resources/Robot_Parkour_Learning.pdf\">Paper</a> <a href=\"https://github.com/ZiwenZhuang/parkour\">Code</a> <a href=\"https://robot-parkour.github.io/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"203\" src=\"/__local/2/C7/44/FD17729F867D5B33D4405BF4E11_6D2E40F9_42314.png\" vsbhref=\"vurl\" vurl=\"/_vsl/2C744FD17729F867D5B33D4405BF4E11/6D2E40F9/42314\" vheight=\"203\" vwidth=\"333\" orisrc=\"/__local/2/C7/44/FD17729F867D5B33D4405BF4E11_6D2E40F9_42314.png\" class=\"img_vsb_content\"></p>\n<p><b>Diff-Foley: Synchronized Video-to-Audio Synthesis with Latent Diffusion Models</b></p>\n<p>Simian Luo, Chuanhao Yan, Chenxu Hu, Hang Zhao</p>\n<p><b>NeurIPS 2023</b></p>\n<p><a href=\"https://arxiv.org/abs/2306.17203v1\">Paper</a> <a href=\"https://diff-foley.github.io/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"267\" height=\"236\" src=\"/__local/F/18/BF/D89DAA34E20C41BB12302213E32_BDC528B3_3DB60.png\" vsbhref=\"vurl\" vurl=\"/_vsl/F18BFD89DAA34E20C41BB12302213E32/BDC528B3/3DB60\" vheight=\"236\" vwidth=\"267\" orisrc=\"/__local/F/18/BF/D89DAA34E20C41BB12302213E32_BDC528B3_3DB60.png\" class=\"img_vsb_content\"></p>\n<p><b>Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving</b></p>\n<p>Xiaoyu Tian, Tao Jiang, Longfei Yun, Yucheng Mao, Huitong Yang,</p>\n<p>Yue Wang, Yilun Wang, Hang Zhao</p>\n<p><b>NeurIPS Dataset Track 2023</b></p>\n<p><a href=\"https://arxiv.org/abs/2304.14365\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/Occ3D/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"166\" src=\"/__local/A/15/D2/E0EAC7A9C2E6C8BB9F5A2699B27_97A6EA49_36219.png\" vsbhref=\"vurl\" vurl=\"/_vsl/A15D2E0EAC7A9C2E6C8BB9F5A2699B27/97A6EA49/36219\" vheight=\"166\" vwidth=\"333\" orisrc=\"/__local/A/15/D2/E0EAC7A9C2E6C8BB9F5A2699B27_97A6EA49_36219.png\" class=\"img_vsb_content\"></p>\n<p><b>ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory</b></p>\n<p>Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, Hang Zhao</p>\n<p><b>LLM@IJCAI 2023</b></p>\n<p><a href=\"https://arxiv.org/abs/2306.03901\">Paper</a> <a href=\"https://chatdatabase.github.io/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"200\" height=\"199\" src=\"/__local/8/FD/83/B272E0DA32C6E062D6E9CF4FCE3_47B151D4_26FF8.png\" vsbhref=\"vurl\" vurl=\"/_vsl/8FD83B272E0DA32C6E062D6E9CF4FCE3/47B151D4/26FF8\" vheight=\"199\" vwidth=\"200\" orisrc=\"/__local/8/FD/83/B272E0DA32C6E062D6E9CF4FCE3_47B151D4_26FF8.png\" class=\"img_vsb_content\"></p>\n<p><b>VCAD: Vision-Centric Autonomous Driving</b> Hot</p>\n<p>Hang Zhao, Yue Wang, Yilun Wang, Justin Solomon, Vitor Guizilini, et al.</p>\n<p><i>\"A research effort pushing the frontiers of camera-centric autonomous driving technology.\"</i></p>\n<p><a href=\"https://vcad-ai.github.io/\">Project</a> <a href=\"/system/site/column/news/addnews.jsp?wbnewsid=3657&amp;newsposition=news#/\">Workshop</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"195\" src=\"/__local/7/5D/27/764E91FF606F25891F9634A01CF_17D78B3F_3F94F.png\" vsbhref=\"vurl\" vurl=\"/_vsl/75D27764E91FF606F25891F9634A01CF/17D78B3F/3F94F\" vheight=\"195\" vwidth=\"333\" orisrc=\"/__local/7/5D/27/764E91FF606F25891F9634A01CF_17D78B3F_3F94F.png\" class=\"img_vsb_content\"></p>\n<p><b>Neural Map Prior for Autonomous Driving</b></p>\n<p>Xuan Xiong, Yicheng Liu, Tianyuan Yuan, Yue Wang, Yilun Wang, Hang Zhao</p>\n<p><b>CVPR 2023</b></p>\n<p><i>\"A neural representation of HD maps to improve local map inference.\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2304.08481\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/neural_map_prior/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"134\" src=\"/__local/2/B3/04/91B75ABB7FAFE6452ACE6B2F95D_3F141F54_2BB2C.png\" vsbhref=\"vurl\" vurl=\"/_vsl/2B30491B75ABB7FAFE6452ACE6B2F95D/3F141F54/2BB2C\" vheight=\"134\" vwidth=\"333\" orisrc=\"/__local/2/B3/04/91B75ABB7FAFE6452ACE6B2F95D_3F141F54_2BB2C.png\" class=\"img_vsb_content\"></p>\n<p><b>ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries</b></p>\n<p>Junru Gu*, Chenxu Hu*, Tianyuan Zhang, Xuanyao Chen, Yilun Wang, Yue Wang, Hang Zhao</p>\n<p><b>CVPR 2023</b></p>\n<p><i>\"Vision-based trajectory prediction autonomous driving.\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2208.01582\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/ViP3D/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"153\" src=\"/__local/2/CD/C6/13CD7FE09F418600222F9E2B58D_5AD6F54F_31E44.png\" vsbhref=\"vurl\" vurl=\"/_vsl/2CDC613CD7FE09F418600222F9E2B58D/5AD6F54F/31E44\" vheight=\"153\" vwidth=\"333\" orisrc=\"/__local/2/CD/C6/13CD7FE09F418600222F9E2B58D_5AD6F54F_31E44.png\" class=\"img_vsb_content\"></p>\n<p><b>VectorMapNet: End-to-end Vectorized HD Map Learning</b></p>\n<p>Yicheng Liu, Tianyuan Yuan, Yue Wang, Yilun Wang, Hang Zhao</p>\n<p><b>ICML 2023</b></p>\n<p><i>\"Vectorized mapping from onboard sensors!\"</i></p>\n<p><a href=\"https://arxiv.org/pdf/2206.08920.pdf\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/vectormapnet/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"240\" height=\"180\" src=\"/__local/8/5A/9D/DCEF9CC1CA9B3CDF56823184B28_24B0F824_2A522.png\" vsbhref=\"vurl\" vurl=\"/_vsl/85A9DDCEF9CC1CA9B3CDF56823184B28/24B0F824/2A522\" vheight=\"180\" vwidth=\"240\" orisrc=\"/__local/8/5A/9D/DCEF9CC1CA9B3CDF56823184B28_24B0F824_2A522.png\" class=\"img_vsb_content\"></p>\n<p><b>InterSim: Interactive Traffic Simulation via Explicit Relation Modeling</b></p>\n<p>Qiao Sun, Xin Huang, Brian C Williams, Hang Zhao</p>\n<p><b>IROS 2022</b></p>\n<p><i>\"Towards closed-loop behavior simulation.\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2210.14413\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/InterSim/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"240\" height=\"240\" src=\"/__local/3/0B/22/90DEDD21D07E62DF59C75A93CB9_F163D58E_386B7.png\" vsbhref=\"vurl\" vurl=\"/_vsl/30B2290DEDD21D07E62DF59C75A93CB9/F163D58E/386B7\" vheight=\"240\" vwidth=\"240\" orisrc=\"/__local/3/0B/22/90DEDD21D07E62DF59C75A93CB9_F163D58E_386B7.png\" class=\"img_vsb_content\"></p>\n<p><b>M2I: From Factored Marginal Trajectory Prediction to Interactive Prediction</b></p>\n<p>Qiao Sun, Xin Huang, Junru Gu, Brian C Williams, Hang Zhao</p>\n<p><b>CVPR 2022</b></p>\n<p><i>\"Towards interactive motion prediction.\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2202.118844\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/M2I/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"240\" height=\"240\" src=\"/__local/5/09/C5/FF3F71719225F03C85C64ADCDEF_B4741F76_386B7.png\" vsbhref=\"vurl\" vurl=\"/_vsl/509C5FF3F71719225F03C85C64ADCDEF/B4741F76/386B7\" vheight=\"240\" vwidth=\"240\" orisrc=\"/__local/5/09/C5/FF3F71719225F03C85C64ADCDEF_B4741F76_386B7.png\" class=\"img_vsb_content\"></p>\n<p><b>HDMapNet: An Online HD Map Construction and Evaluation Framework</b></p>\n<p>Qi Li, Yue Wang, Yilun Wang, Hang Zhao</p>\n<p><b>CVPR 2021 Workshop best paper, ICRA 2022</b></p>\n<p><i>\"HD map learning from onboard sensors!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2107.06307\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/HDMapNet/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"138\" src=\"/__local/D/A7/23/027F09E5543F5696FB1E7ABBF4D_3F6BB258_2D00C.png\" vsbhref=\"vurl\" vurl=\"/_vsl/DA723027F09E5543F5696FB1E7ABBF4D/3F6BB258/2D00C\" vheight=\"138\" vwidth=\"333\" orisrc=\"/__local/D/A7/23/027F09E5543F5696FB1E7ABBF4D_3F6BB258_2D00C.png\" class=\"img_vsb_content\"></p>\n<p><b>Neural Dubber: Dubbing for Videos According to Scripts</b></p>\n<p>Chenxu Hu, Qiao Tian, Tingle Li, Yuping Wang, Yuxuan Wang, Hang Zhao</p>\n<p><b>NeurIPS 2021</b></p>\n<p><i>\"Automatic video dubbing driven by a neural network!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2110.08243\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/NeuralDubber/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"240\" height=\"240\" src=\"/__local/C/D6/08/B9126D9663C96F1E4E446333D79_74502B49_386B7.png\" vsbhref=\"vurl\" vurl=\"/_vsl/CD608B9126D9663C96F1E4E446333D79/74502B49/386B7\" vheight=\"240\" vwidth=\"240\" orisrc=\"/__local/C/D6/08/B9126D9663C96F1E4E446333D79_74502B49_386B7.png\" class=\"img_vsb_content\"></p>\n<p><b>DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries</b> Hot</p>\n<p>Yue Wang, Vitor Campagnolo Guizilini, Tianyuan Zhang, Yilun Wang, Hang Zhao, Justin Solomon</p>\n<p><b>CoRL 2021</b></p>\n<p><i>\"A new paradigm of 3D object detection from 2D images!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2110.08243\">Paper</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"267\" height=\"224\" src=\"/__local/1/15/C5/E3DB0F1EFD012D747EFE16982ED_A9D26046_3A938.png\" vsbhref=\"vurl\" vurl=\"/_vsl/115C5E3DB0F1EFD012D747EFE16982ED/A9D26046/3A938\" vheight=\"224\" vwidth=\"267\" orisrc=\"/__local/1/15/C5/E3DB0F1EFD012D747EFE16982ED_A9D26046_3A938.png\" class=\"img_vsb_content\"></p>\n<p><b>On Feature Decorrelation in Self-Supervised Learning</b> Hot</p>\n<p>Tianyu Hua, Wenxiao Wang, Zihui Xue, Yue Wang, Sucheng Ren, Hang Zhao</p>\n<p><b>ICCV 2021 Oral</b></p>\n<p><i>\"It reveals the connection between model collapse and feature correlations!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2105.00470\">Paper</a> <a href=\"https://tsinghua-mars-lab.github.io/decorr/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"187\" src=\"/__local/B/61/97/9D1C8FF7212BF06246CF59FE07C_DEC8B08C_3CF9B.png\" vsbhref=\"vurl\" vurl=\"/_vsl/B61979D1C8FF7212BF06246CF59FE07C/DEC8B08C/3CF9B\" vheight=\"187\" vwidth=\"333\" orisrc=\"/__local/B/61/97/9D1C8FF7212BF06246CF59FE07C_DEC8B08C_3CF9B.png\" class=\"img_vsb_content\"></p>\n<p><b>Large Scale Interactive Motion Forecasting for Autonomous Driving: The Waymo Open Motion Dataset</b></p>\n<p>Scott Ettinger, et al.</p>\n<p><b>ICCV 2021 Oral</b></p>\n<p><a href=\"https://arxiv.org/abs/2104.10133\">Paper</a> <a href=\"https://blog.waymo.com/2021/03/expanding-waymo-open-dataset-with-interactive-scenario-data-and-new-challenges.html\">Waymo Blog</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"222\" src=\"/__local/5/A1/A6/7BCDB7F5CF9414AB1F468984D2F_1832886D_48627.png\" vsbhref=\"vurl\" vurl=\"/_vsl/5A1A67BCDB7F5CF9414AB1F468984D2F/1832886D/48627\" vheight=\"222\" vwidth=\"333\" orisrc=\"/__local/5/A1/A6/7BCDB7F5CF9414AB1F468984D2F_1832886D_48627.png\" class=\"img_vsb_content\"></p>\n<p><b>DenseTNT: End-to-end Trajectory Prediction from Dense Goal Sets</b></p>\n<p>Junru Gu, Chen Sun, Hang Zhao</p>\n<p><b>ICCV 2021</b></p>\n<p><i>\"A SOTA anchor-free and end-to-end multi-trajectory prediction model\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2108.09640\">Paper</a> <a href=\"https://arxiv.org/abs/2106.14160\">Challenge Report</a> <a href=\"https://tsinghua-mars-lab.github.io/DenseTNT/\">Project</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"267\" height=\"275\" src=\"/__local/A/62/24/5F365088792EC5F3B8AA23FBD04_61DB16D8_47E7C.png\" vsbhref=\"vurl\" vurl=\"/_vsl/A62245F365088792EC5F3B8AA23FBD04/61DB16D8/47E7C\" vheight=\"275\" vwidth=\"267\" orisrc=\"/__local/A/62/24/5F365088792EC5F3B8AA23FBD04_61DB16D8_47E7C.png\" class=\"img_vsb_content\"></p>\n<p><b>TNT: Target-driveN Trajectory Prediction</b> Hot</p>\n<p>Hang Zhao, Jiyang Gao, Tian Lan, Chen Sun, Benjamin Sapp,</p>\n<p>Balakrishnan Varadarajan, Yue Shen, Yi Shen, Yuning Chai,</p>\n<p>Cordelia Schmid, Congcong Li, Dragomir Anguelov</p>\n<p>Conference on Robot Learning (<b>CoRL</b>) 2020</p>\n<p><i>\"A new motion prediction framework for self-driving!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/2008.08294\">Paper</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"187\" src=\"/__local/B/EA/3E/B46A39B879F9706C96EF6C3CCA8_4EA11B8B_3CF9B.png\" vsbhref=\"vurl\" vurl=\"/_vsl/BEA3EB46A39B879F9706C96EF6C3CCA8/4EA11B8B/3CF9B\" vheight=\"187\" vwidth=\"333\" orisrc=\"/__local/B/EA/3E/B46A39B879F9706C96EF6C3CCA8_4EA11B8B_3CF9B.png\" class=\"img_vsb_content\"></p>\n<p><b>VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized Representation</b> Hot</p>\n<p>Jiyang Gao, Chen Sun, Hang Zhao, Yi Shen,</p>\n<p>Dragomir Anguelov, Congcong Li, Cordelia Schmid</p>\n<p>In Proc. Computer Vision and Pattern Recognition (<b>CVPR</b>) 2020</p>\n<p><a href=\"https://openaccess.thecvf.com/content_CVPR_2020/papers/Gao_VectorNet_Encoding_HD_Maps_and_Agent_Dynamics_From_Vectorized_Representation_CVPR_2020_paper.pdf\">Paper</a> <a href=\"https://blog.waymo.com/2020/05/vectornet.html\">Waymo Blog</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"187\" src=\"/__local/3/CB/AD/9A15DF072442893CA2B5279B464_7E55D851_3CF9B.png\" vsbhref=\"vurl\" vurl=\"/_vsl/3CBAD9A15DF072442893CA2B5279B464/7E55D851/3CF9B\" vheight=\"187\" vwidth=\"333\" orisrc=\"/__local/3/CB/AD/9A15DF072442893CA2B5279B464_7E55D851_3CF9B.png\" class=\"img_vsb_content\"></p>\n<p><b>Scalability in Perception for Autonomous Driving: Waymo Open Dataset</b></p>\n<p>Pei Sun et al.</p>\n<p>In Proc. Computer Vision and Pattern Recognition (<b>CVPR</b>) 2020</p>\n<p>Seattle (virtual), June. 2020</p>\n<p><a href=\"https://waymo.com/open/\">Project Page</a> <a href=\"https://waymo.com/open/challenges\">Challenges</a> <a href=\"https://arxiv.org/abs/1912.04838\">Paper</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"267\" height=\"200\" src=\"/__local/3/51/65/1DD398E9031FFEC756A5936563A_86A3F481_344D7.png\" vsbhref=\"vurl\" vurl=\"/_vsl/351651DD398E9031FFEC756A5936563A/86A3F481/344D7\" vheight=\"200\" vwidth=\"267\" orisrc=\"/__local/3/51/65/1DD398E9031FFEC756A5936563A_86A3F481_344D7.png\" class=\"img_vsb_content\"></p>\n<p><b>HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization</b></p>\n<p>Hang Zhao, Zhicheng Yan, Lorenzo Torresani, Antonio Torralba</p>\n<p>In Proc. International Conference on Computer Vision (<b>ICCV</b>)</p>\n<p>Seoul, Korea, Oct. 2019</p>\n<p><i>\"A large-scale dataset for temporal action localization and recognition.\"</i></p>\n<p><a href=\"https://arxiv.org/abs/1712.09374\">Paper (arXiv)</a> <a href=\"http://hacs.csail.mit.edu/\">Project Page</a> <a href=\"https://github.com/hangzhaomit/HACS-dataset\">GitHub Page</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"294\" height=\"218\" src=\"/__local/0/10/33/DA1BDE0A74D5AFD069B05B71F48_7548BFCB_3EC3A.png\" vsbhref=\"vurl\" vurl=\"/_vsl/01033DA1BDE0A74D5AFD069B05B71F48/7548BFCB/3EC3A\" vheight=\"218\" vwidth=\"294\" orisrc=\"/__local/0/10/33/DA1BDE0A74D5AFD069B05B71F48_7548BFCB_3EC3A.png\" class=\"img_vsb_content\"></p>\n<p><b>The Sound of Pixels</b> Hot</p>\n<p>Hang Zhao, Chuang Gan, Andrew Rouditchenko, Carl Vondrick, Josh McDermott, Antonio Torralba</p>\n<p>In Proc. European Conference on Computer Vision (<b>ECCV</b>)</p>\n<p>Munich, Germany, Sep. 2018</p>\n<p><i>\"Listen to the sound of pixels!\"</i></p>\n<p><a href=\"https://arxiv.org/abs/1804.03160\">Paper (arXiv)</a> <a href=\"http://sound-of-pixels.csail.mit.edu/\">Project Page</a> <a href=\"https://github.com/hangzhaomit/Sound-of-Pixels\">Code</a> <a href=\"http://news.mit.edu/2018/ai-editing-music-videos-pixelplayer-csail-0705\">News Coverage</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"333\" height=\"167\" src=\"/__local/A/22/8B/8B82FBEF8AC255C5510AFE825A3_EAF7FED3_3674E.png\" vsbhref=\"vurl\" vurl=\"/_vsl/A228B8B82FBEF8AC255C5510AFE825A3/EAF7FED3/3674E\" vheight=\"167\" vwidth=\"333\" orisrc=\"/__local/A/22/8B/8B82FBEF8AC255C5510AFE825A3_EAF7FED3_3674E.png\" class=\"img_vsb_content\"></p>\n<p><b>Through-Wall Human Pose Estimation Using Radio Signals</b> Hot</p>\n<p>Mingmin Zhao, Tianhong Li, Mohammad Alsheikh, Yonglong Tian, Hang Zhao,</p>\n<p>Antonio Torralba, Dina Katabi</p>\n<p>In Proc. Computer Vision and Pattern Recognition (<b>CVPR</b>)</p>\n<p>Salt Lake City, Utah, June. 2018</p>\n<p><a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhao_Through-Wall_Human_Pose_CVPR_2018_paper.pdf\">Paper</a> <a href=\"http://rfpose.csail.mit.edu/\">Project Page</a> <a href=\"http://news.mit.edu/2018/artificial-intelligence-senses-people-through-walls-0612\">News Coverage</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"294\" height=\"162\" src=\"/__local/5/57/6A/569EFC6B513DA06E151C5A72834_EEED8280_2EA58.png\" vsbhref=\"vurl\" vurl=\"/_vsl/5576A569EFC6B513DA06E151C5A72834/EEED8280/2EA58\" vheight=\"162\" vwidth=\"294\" orisrc=\"/__local/5/57/6A/569EFC6B513DA06E151C5A72834_EEED8280_2EA58.png\" class=\"img_vsb_content\"></p>\n<p><b>Scene Parsing through ADE20K Dataset</b> Hot</p>\n<p>Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, Antonio Torralba</p>\n<p>In Proc. Computer Vision and Pattern Recognition (<b>CVPR</b>)</p>\n<p>Honolulu, Hawaii, July. 2017</p>\n<p><a href=\"http://people.csail.mit.edu/bzhou/publication/scene-parse-camera-ready.pdf\">Paper</a> <a href=\"http://groups.csail.mit.edu/vision/datasets/ADE20K/\">Dataset</a> <a href=\"https://github.com/CSAILVision/sceneparsing\">Code</a> <a href=\"http://scenesegmentation.csail.mit.edu/\">Online Demo</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"294\" height=\"195\" src=\"/__local/B/56/67/7396882A467206571E49A74A374_02284D81_38252.png\" vsbhref=\"vurl\" vurl=\"/_vsl/B56677396882A467206571E49A74A374/02284D81/38252\" vheight=\"195\" vwidth=\"294\" orisrc=\"/__local/B/56/67/7396882A467206571E49A74A374_02284D81_38252.png\" class=\"img_vsb_content\"></p>\n<p><b>Semantic Understanding of Scenes through the ADE20K Dataset</b></p>\n<p>Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso, Antonio Torralba</p>\n<p>International Journal on Computer Vision 2018 (<b>IJCV</b>)</p>\n<p><b>ILSVRC'16 MIT Scene Parsing Challenge</b></p>\n<p><i>\"I co-organized the scene parsing challenge at ILSVRC'16. Check out our dataset now!\"</i></p>\n<p><a href=\"http://arxiv.org/abs/1608.05442\">Paper (arXiv)</a> <a href=\"http://groups.csail.mit.edu/vision/datasets/ADE20K/\">Dataset</a> <a href=\"http://sceneparsing.csail.mit.edu/\">Benchmark Page</a> <a href=\"http://sceneparsing.csail.mit.edu/index_challenge.html\">Challenge Page</a> <a href=\"https://github.com/CSAILVision/sceneparsing\">GitHub Page</a> <a href=\"http://scenesegmentation.csail.mit.edu/\">Online Demo</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"294\" height=\"215\" src=\"/__local/2/88/64/67F77E425F52194E98859B0C593_8C80861E_3DE63.png\" vsbhref=\"vurl\" vurl=\"/_vsl/2886467F77E425F52194E98859B0C593/8C80861E/3DE63\" vheight=\"215\" vwidth=\"294\" orisrc=\"/__local/2/88/64/67F77E425F52194E98859B0C593_8C80861E_3DE63.png\" class=\"img_vsb_content\"></p>\n<p><b>Loss Functions for Neural Networks for Image Processing </b>Hot</p>\n<p>Hang Zhao, Orazio Gallo, Iuri Frosio and Jan Kautz</p>\n<p>arXiv:1511.08861</p>\n<p>IEEE Transactions on Computational Imaging 2017 (<b>TCI</b>)</p>\n<p><i>\"How important are loss functions for image processing tasks in deep neural nets?\"</i></p>\n<p><a href=\"http://ieeexplore.ieee.org/iel7/6745852/6960042/07797130.pdf\">Paper (Journal)</a> <a href=\"http://arxiv.org/abs/1511.08861\">Paper (arXiv)</a> <a href=\"http://research.nvidia.com/publication/loss-functions-image-restoration-neural-networks\">Project Page</a> <a href=\"https://github.com/NVlabs/PL4NN\">Code</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"294\" height=\"147\" src=\"/__local/E/20/5E/FC70E7CDDA4D8B94955CAB67F66_35653B2B_2A549.png\" vsbhref=\"vurl\" vurl=\"/_vsl/E205EFC70E7CDDA4D8B94955CAB67F66/35653B2B/2A549\" vheight=\"147\" vwidth=\"294\" orisrc=\"/__local/E/20/5E/FC70E7CDDA4D8B94955CAB67F66_35653B2B_2A549.png\" class=\"img_vsb_content\"></p>\n<p><b>Duckietown: an Open, Inexpensive and Flexible Platform for Autonomy Education and Research</b></p>\n<p>IEEE International Conference on Robotics and Automation (<b>ICRA</b>)</p>\n<p>Singapore, May. 2017</p>\n<p><i>\"We are building an open-source education and research platform for autonomous driving. \"</i></p>\n<p><a href=\"https://hangzhaomit.github.io/papers/duckietown.pdf\">Paper</a> <a href=\"https://youtu.be/-TwocCeJUe8\">Video</a> <a href=\"https://duckietown.mit.edu/\">Project Page</a> <a href=\"https://github.com/duckietown/Software\">Code</a> <a href=\"http://news.mit.edu/2016/self-driving-cars-meet-rubber-duckies-0420\">News Coverage</a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"267\" height=\"230\" src=\"/__local/7/DF/AF/70C145C50DA106A747725CC9797_79FB7D0A_3C252.png\" vsbhref=\"vurl\" vurl=\"/_vsl/7DFAF70C145C50DA106A747725CC9797/79FB7D0A/3C252\" vheight=\"230\" vwidth=\"267\" orisrc=\"/__local/7/DF/AF/70C145C50DA106A747725CC9797_79FB7D0A_3C252.png\" class=\"img_vsb_content\"></p>\n<p><b>Unbounded High Dynamic Range Photography using a Modulo Camera </b>Hot</p>\n<p>Hang Zhao, Boxin Shi, Christy Fernandez-Cull, Sai-Kit Yeung and Ramesh Raskar</p>\n<p>In Proc. International Conference on Computational Photography (<b>ICCP</b>)</p>\n<p>Houston, USA, Apr. 2015 (Acceptance Rate: 24%)</p>\n<p>Oral Presentation [<a href=\"https://hangzhaomit.github.io/images/ICCP2015Award.jpg\"><b>Best Paper runner-up</b></a>]</p>\n<p class=\"vsbcontent_end\"><a href=\"https://hangzhaomit.github.io/papers/moduloUHDR.pdf\">Paper</a> <a href=\"https://hangzhaomit.github.io/posters/ICCP15_Poster.pdf\">Poster</a> <a href=\"http://web.media.mit.edu/~hangzhao/videos/ICCP15_audio.mp4\">Video</a> <a href=\"http://web.media.mit.edu/~hangzhao/modulo.html\">Project Page</a> <a href=\"/system/site/column/news/addnews.jsp?wbnewsid=3657&amp;newsposition=news#news\">News Coverage</a></p></div>\n \n  </div>\n  \n    <div class=\"box box0 box3 aos-init\" data-aos=\"fade-up\">\n       \n         <h3 class=\"h3-5 flex\"><img src=\"../../images/h3-5.png\" alt=\"\">Teaching</h3>\n                <div class=\"arc-con arc-cons1\"><h2></h2>\n<p class=\"vsbcontent_start\">· [Tsinghua] Advances in Autonomous Driving and Intelligent Vehicles (Lecturer)</p>\n<p>· [Tsinghua] Introduction to Multimedia Computing (Lecturer)</p>\n<p>· <a href=\"http://6.869.csail.mit.edu/fa16/\">[MIT 6.869] Advances in Computer Vision (Teaching Assistant)</a></p>\n<p>· <a href=\"http://duckietown.mit.edu/\">[MIT 2.166] Autonomous Vehicles, also known as \"Duckietown\" (Course Developer, Teaching Assistant)</a></p>\n<p>· [MIT 6.870] Smartphone Vision (Teaching Assistant)</p>\n<p class=\"vsbcontent_end\">· <a href=\"http://news.mit.edu/2015/2.007-competition-hack-future-0508\">[MIT 2.007] Design and Manufacturing I (Teaching Assistant)</a></p></div>\n \n  </div>\n  \n    <div class=\"box box0 box3 aos-init\" data-aos=\"fade-up\">\n       \n         <h3 class=\"h3-5 flex\"><img src=\"../../images/h3-5.png\" alt=\"\">Professional Activities</h3>\n                <div class=\"arc-con arc-cons1\"><h2></h2>\n<p class=\"vsbcontent_start\">· Co-organizer of <a href=\"/system/site/column/news/addnews.jsp?wbnewsid=3657&amp;newsposition=news#/\">Workshop on Vision-Centric Autonomous Driving (VCAD)</a> at ECCV 2024.</p>\n<p>· Co-organizer of <a href=\"https://vision-language-adr.github.io/\">Workshop on Vision and Language for Autonomous Driving and Robotics</a> at CVPR 2024.</p>\n<p>· Co-organizer of <a href=\"http://sightsound.org/\">Workshop on Sight and Sound</a> at CVPR 2024.</p>\n<p>· Co-organizer of <a href=\"/system/site/column/news/addnews.jsp?wbnewsid=3657&amp;newsposition=news#/\">Workshop on Vision-Centric Autonomous Driving (VCAD)</a> at CVPR 2023.</p>\n<p>· Co-organizer of <a href=\"http://sightsound.org/\">Workshop on Sight and Sound</a> at CVPR 2023.</p>\n<p>· Workshop co-chair (organizing committee) of <a href=\"https://iclr.cc/\">ICLR 2023</a>.</p>\n<p>· Co-organizer of <a href=\"http://sightsound.org/\">Workshop on Sight and Sound</a> at CVPR 2022.</p>\n<p>· Co-organizer of <a href=\"https://hangzhaomit.github.io/\">HACS Temporal Action Localization Challenge</a> at <a href=\"http://activity-net.org/challenges/2020/\">Workshop on International Challenge on Activity Recognition</a> at CVPR 2020.</p>\n<p>· Co-organizer of <a href=\"http://sightsound.org/\">Workshop on Sight and Sound</a> at CVPR 2020.</p>\n<p>· Co-organizer of <a href=\"https://sites.google.com/view/multimodalvideo/\">Workshop on Multi-modal Video Analysis and Moments in Time Challenge</a> at ICCV 2019.</p>\n<p>· Co-organizer of <a href=\"https://lidchallenge.github.io/\">Weakly Supervised Learning for Real-World Computer Vision Applications and the 1st Learning from Imperfect Data (LID) Challenge</a> at CVPR 2019.</p>\n<p>· Co-organizer of <a href=\"http://placeschallenge.csail.mit.edu/\">Places Challenge 2017</a>.</p>\n<p>· Co-organizer of <a href=\"https://places-coco2017.github.io/\">Joint COCO and Places Recognition Challenge Workshop</a> at ICCV 2017.</p>\n<p>· Co-organizer of <a href=\"http://sceneparsing.csail.mit.edu/index_challenge.html\">MIT Scene Parsing Challenge 2016</a>.</p>\n<p>· Co-organizer of <a href=\"http://image-net.org/challenges/LSVRC/2016/index\">ILSVRC'16 challenge workshop</a> at ECCV 2016.</p>\n<p>· Journal reviewer for TPAMI, IJCV, TIP, CVIU, TCI, OE, etc.</p>\n<p>· Conference reviewer for CVPR, ICCV, ECCV, NIPS, ICML, ICLR, etc.</p>\n<p class=\"vsbcontent_end\">· Co-chair of <a href=\"https://sites.google.com/view/visionseminar\">MIT Vision Seminar</a>.</p></div>\n \n  </div>\n  \n    <div class=\"box box0 box3 aos-init\" data-aos=\"fade-up\">\n       \n         <h3 class=\"h3-5 flex\"><img src=\"../../images/h3-5.png\" alt=\"\">Talks</h3>\n                <div class=\"arc-con arc-cons1\"><h2></h2>\n<p class=\"vsbcontent_start\">· Invited talk at ECCV Workshop on Autonomous Vehicles meet Multimodal Foundation Models, Oct 2024.</p>\n<p>· Invited talk at ICCV Workshop on Visual Learning of Sounds in Spaces (AV4D), Oct 2023.</p>\n<p>· Invited talk at CVPR Workshop on Autonomous Driving (WAD), June 2023.</p>\n<p>· Invited talk at VALSE Workshop on Autonomous Driving, June 2023.</p>\n<p>· Invited talk at ICLR Workshop on Representation for Autonomous Driving, May 2023.</p>\n<p>· Invited talk at NeuRIPS Workshop on Machine learning for Autonomous Driving (ML4AD), December 2022.</p>\n<p>· Invited talk at IROS Workshop on Behavior-driven Autonomous Driving in Unstructured Environments, Oct 2022.</p>\n<p>· Invited talk at CVPR Tutorial on OpenMMLab, June 2022.</p>\n<p>· Invited talk at VALSE APR on Autonomous Driving, June 2022.</p>\n<p>· Invited talk at VALSE Workshop on Multimodal Learning, June 2022.</p>\n<p>· Invited talk at ICCV Workshop on Benchmarking Trajectory Forecasting Models, Oct 2021.</p>\n<p>· Invited talk at CVPR Workshop on Autonomous Driving, June 2021.</p>\n<p>· Invited talk at Samsung Research Lab, UK, April 2021.</p>\n<p>· Invited talk at Amazon Alexa, May 2019.</p>\n<p>· Invited talk at Samsung Workshop at MIT, April 2019.</p>\n<p>· Invited talk at Machine Intelligence Conference, March 2019.</p>\n<p>· Invited talk at PHILIPS, Feburary 2019.</p>\n<p>· Invited talk at VALSE, June 2018.</p>\n<p>· Invited talk at Harvard vision seminar, May 2018.</p>\n<p>· Invited talk at Google Cambridge, April 2018.</p>\n<p>· Invited talk at MIT graphics seminar, September 2015.</p>\n<p>In Chinese:</p>\n<p>· Invited talk at TechBeat on BEV Perception for Vision-Centric Autonomous Driving, March 2022. <a href=\"https://www.techbeat.net/talk-info?id=646\">[Recording]</a></p>\n<p>· Invited talk at TechBeat on Motion Prediction for Autonomous Driving, December 2020. <a href=\"https://www.techbeat.net/talk-info?id=478\">[Recording]</a></p>\n<p class=\"vsbcontent_end\">· Invited talk at TechBeat on Cross-modal Audio-visual Self-supervised Learning, June 2018. <a href=\"https://www.techbeat.net/talk-info?id=248\">[Recording]</a></p></div>\n \n  </div>\n  \n    <div class=\"box box0 box3 aos-init\" data-aos=\"fade-up\">\n       \n         <h3 class=\"h3-5 flex\"><img src=\"../../images/h3-5.png\" alt=\"\">Resources</h3>\n                <div class=\"arc-con arc-cons1\"><h2></h2>\n<p class=\"vsbcontent_start\">· Open Source Codebase: <a href=\"https://github.com/CSAILVision/semantic-segmentation-pytorch/\">Semantic Segmentation in PyTorch</a></p>\n<p class=\"vsbcontent_end\">· Poster: <a href=\"https://hangzhaomit.github.io/posters/2015Spring_Poster.pdf\">Computational Photography with Novel Camera Sensors</a></p>\n<h3></h3></div>\n \n  </div>\n  \n    <div class=\"box box0 box3 aos-init\" data-aos=\"fade-up\">\n       \n         <h3 class=\"h3-5 flex\"><img src=\"../../images/h3-5.png\" alt=\"\">Current and Past Affiliations</h3>\n                <div class=\"arc-con arc-cons1\"><h3></h3>\n<p class=\"vsbcontent_start\"><a href=\"https://www.tsinghua.edu.cn/en/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"127\" height=\"127\" src=\"/__local/C/5C/43/E5129EE9AA8B5734726EAD81047_EC469F4A_FD35.png\" vsbhref=\"vurl\" vurl=\"/_vsl/C5C43E5129EE9AA8B5734726EAD81047/EC469F4A/FD35\" vheight=\"127\" vwidth=\"127\" orisrc=\"/__local/C/5C/43/E5129EE9AA8B5734726EAD81047_EC469F4A_FD35.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"http://csail.mit.edu/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"186\" height=\"127\" src=\"/__local/3/2A/BB/E503DBED423F3F5362B6B0E5680_B86209CC_1727E.png\" vsbhref=\"vurl\" vurl=\"/_vsl/32ABBE503DBED423F3F5362B6B0E5680/B86209CC/1727E\" vheight=\"127\" vwidth=\"186\" orisrc=\"/__local/3/2A/BB/E503DBED423F3F5362B6B0E5680_B86209CC_1727E.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"http://media.mit.edu/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"195\" height=\"127\" src=\"/__local/4/F9/0B/781B049230825FAAEA7E7E0D20E_FED6F24B_1846B.png\" vsbhref=\"vurl\" vurl=\"/_vsl/4F90B781B049230825FAAEA7E7E0D20E/FED6F24B/1846B\" vheight=\"127\" vwidth=\"195\" orisrc=\"/__local/4/F9/0B/781B049230825FAAEA7E7E0D20E_FED6F24B_1846B.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"http://www.mit.edu/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"175\" height=\"101\" src=\"/__local/D/AD/29/91A5928721486A5C3049E425AB6_7397F529_11554.png\" vsbhref=\"vurl\" vurl=\"/_vsl/DAD2991A5928721486A5C3049E425AB6/7397F529/11554\" vheight=\"101\" vwidth=\"175\" orisrc=\"/__local/D/AD/29/91A5928721486A5C3049E425AB6_7397F529_11554.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"http://www.ucla.edu/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"238\" height=\"114\" src=\"/__local/4/B6/04/5AB9F668CAA7D0228491FED1F91_C4A66110_1A966.png\" vsbhref=\"vurl\" vurl=\"/_vsl/4B6045AB9F668CAA7D0228491FED1F91/C4A66110/1A966\" vheight=\"114\" vwidth=\"238\" orisrc=\"/__local/4/B6/04/5AB9F668CAA7D0228491FED1F91_C4A66110_1A966.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"http://www.zju.edu.cn/english/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"134\" height=\"134\" src=\"/__local/0/42/99/032F2316B473F8E8B6CA2ABE77D_7499D7DD_119D9.png\" vsbhref=\"vurl\" vurl=\"/_vsl/04299032F2316B473F8E8B6CA2ABE77D/7499D7DD/119D9\" vheight=\"134\" vwidth=\"134\" orisrc=\"/__local/0/42/99/032F2316B473F8E8B6CA2ABE77D_7499D7DD_119D9.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"https://research.fb.com/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"186\" height=\"120\" src=\"/__local/F/A7/56/B0EEB18C61474D26C058E8C0E31_8C4785EF_15E13.png\" vsbhref=\"vurl\" vurl=\"/_vsl/FA756B0EEB18C61474D26C058E8C0E31/8C4785EF/15E13\" vheight=\"120\" vwidth=\"186\" orisrc=\"/__local/F/A7/56/B0EEB18C61474D26C058E8C0E31_8C4785EF_15E13.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"https://research.fb.com/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"221\" height=\"147\" src=\"/__local/8/15/A2/0012CB427F78E2B4637C309DD7C_BA13798D_1FD4B.png\" vsbhref=\"vurl\" vurl=\"/_vsl/815A20012CB427F78E2B4637C309DD7C/BA13798D/1FD4B\" vheight=\"147\" vwidth=\"221\" orisrc=\"/__local/8/15/A2/0012CB427F78E2B4637C309DD7C_BA13798D_1FD4B.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"http://www.merl.com/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"215\" height=\"101\" src=\"/__local/9/58/8D/934E8F09A6D490F88B3CE616C2D_263E2BB5_1548C.png\" vsbhref=\"vurl\" vurl=\"/_vsl/9588D934E8F09A6D490F88B3CE616C2D/263E2BB5/1548C\" vheight=\"101\" vwidth=\"215\" orisrc=\"/__local/9/58/8D/934E8F09A6D490F88B3CE616C2D_263E2BB5_1548C.png\" class=\"img_vsb_content\"></p>\n<p><a href=\"http://www.nvidia.com/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"162\" height=\"120\" src=\"/__local/8/1F/05/1C3A111B190ADD71479413C3247_B05DBE2C_13107.png\" vsbhref=\"vurl\" vurl=\"/_vsl/81F051C3A111B190ADD71479413C3247/B05DBE2C/13107\" vheight=\"120\" vwidth=\"162\" orisrc=\"/__local/8/1F/05/1C3A111B190ADD71479413C3247_B05DBE2C_13107.png\" class=\"img_vsb_content\"></p>\n<p class=\"vsbcontent_end\"><a href=\"http://www.tvisioninsights.com/\"></a></p>\n<p class=\"vsbcontent_img imgh\"><img width=\"245\" height=\"107\" src=\"/__local/1/33/E4/48680B1A002409B44B81EECA6B7_B65C7A65_19AFF.png\" vsbhref=\"vurl\" vurl=\"/_vsl/133E448680B1A002409B44B81EECA6B7/B65C7A65/19AFF\" vheight=\"107\" vwidth=\"245\" orisrc=\"/__local/1/33/E4/48680B1A002409B44B81EECA6B7_B65C7A65_19AFF.png\" class=\"img_vsb_content\"></p></div>\n \n  </div>\n  \n</div>\n\n          <div class=\"box box0 box5 aos-init\" data-aos=\"fade-up\">\n            <h3 class=\"h3-5 flex\"><img src=\"../../images/h3-5.png\" alt=\"\">相关资讯</h3>\n            \n\n\n\n\n\n\n\n<script language=\"javascript\" src=\"/system/resource/js/ajax.js\"></script><ul class=\"ls33 flexjs\">\n<li>\n    <a href=\"../../info/1018/4720.htm\" target=\"_blank\" title=\"交叉信息院教师赵行入选《麻省理工科技评论》中国区“35岁以下科技创新35人”\" class=\"a flexjs\">\n                  <div class=\"time flex\">\n                    <h3>05<small>月</small></h3>\n                    <h6>28</h6>\n                  </div>\n                  <div class=\"txt\">\n                    <h4 class=\"l3 h4s3\">交叉信息院教师赵行入选《麻省理工科技评论》中国区“35岁以下科技创新35人”</h4>\n                  </div>\n                </a>\n              </li>\n              \n<li>\n    <a href=\"../../info/1018/1549.htm\" target=\"_blank\" title=\"ChatDB：赵行课题组等提出LLMs符号性记忆框架，复杂推理能力超越ChatGPT\" class=\"a flexjs\">\n                  <div class=\"time flex\">\n                    <h3>06<small>月</small></h3>\n                    <h6>28</h6>\n                  </div>\n                  <div class=\"txt\">\n                    <h4 class=\"l3 h4s3\">ChatDB：赵行课题组等提出LLMs符号性记忆框架，复杂推理能力超越ChatGPT</h4>\n                  </div>\n                </a>\n              </li>\n              \n<li>\n    <a href=\"../../info/1018/1901.htm\" target=\"_blank\" title=\"赵行课题组提出Neural Dubber神经网络配音器，有望让影视后期效率倍增\" class=\"a flexjs\">\n                  <div class=\"time flex\">\n                    <h3>11<small>月</small></h3>\n                    <h6>24</h6>\n                  </div>\n                  <div class=\"txt\">\n                    <h4 class=\"l3 h4s3\">赵行课题组提出Neural Dubber神经网络配音器，有望让影视后期效率倍增</h4>\n                  </div>\n                </a>\n              </li>\n              \n</ul><script>_showDynClickBatch(['dynclicks_u11_4720','dynclicks_u11_1549','dynclicks_u11_1901'],[4720,1549,1901],\"wbnews\", 2110873241)</script>\n\n          </div>\n        </div>\n        <div class=\"right\">\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<script language=\"javascript\" src=\"/system/resource/js/ajax.js\"></script><script language=\"javascript\">_getBatchClickTimes('null',2110873241,'wbnews','u12')</script>\n<script>function seeContenta12(contentid,size,displayid){    document.getElementById(contentid).innerHTML = '[';    for(var i=0;i<=size;i++){        var allcontentid = contentid+(i+1);        if(allcontentid==displayid){            document.getElementById(contentid).innerHTML += \" <span id='\"+allcontentid+\"' name='\"+allcontentid+\"'  >\"+(i+1)+\"</span> \";            document.getElementById(displayid).style.display = 'block';        }else{            document.getElementById(contentid).innerHTML += \" <span style='cursor:pointer' id='\"+allcontentid+\"' name='\"+allcontentid+\"' onclick=seeContenta12('\"+contentid+\"','\"+size+\"','\"+allcontentid+\"')  >\"+(i+1)+\"</span> \";            document.getElementById(allcontentid).style.display = 'none';        }    }    document.getElementById(contentid).innerHTML += ']';}</script>\n\n<script>_addDynClicks('wbnews',2110873241,3657)</script>\n<div class=\"sticky\">\n            <div class=\"box\">\n      \n              <div class=\"con\">\n                <h4>Email</h4>\n                <h6><img src=\"../../zpyx/31str2img.png\" alt=\"\"></h6>\n              </div>\n\n              \n              <div class=\"con\" style=\"display:none;\"></div>\n              <div class=\"con\">\n                <h4>Office</h4>\n                <h6>Tsinghua University Science Park, C19</h6>\n              </div>\n              <div class=\"con\">\n                <h4>Google Scholar</h4>\n                <h6>https://scholar.google.com/citations?user=DmahiOYAAAAJ</h6>\n              </div>\n              \n              <div class=\"con\" style=\"display:none;\"></div>\n              \n              <div class=\"con\" style=\"display:none;\"></div>\n            </div>\n          </div>\n</div>\n      </div>\n    </div>\n  </div>\n\n   <div class=\"footer section fp-auto-height\">\n          <div class=\"wp\"><!-- 版权内容请在本组件\"内容配置-版权\"处填写 -->\n<p>地址：北京市 海淀区 清华大学 信息科学技术楼(FIT楼) 1-208室 100084 电话：010-62781693</p><p>传真： 010-62781693-转2000 邮箱：iiis@mail.tsinghua.edu.cn 版权所有 @ 清华大学交叉信息研究院</p></div>\n        </div>\n</div>\n\n<div class=\"ser-layer\">\n      <span class=\"serclose swi-close-outlined\"></span>\n      <div class=\"serform\"><script type=\"text/javascript\">\n    function _nl_ys_check(){\n        \n        var keyword = document.getElementById('showkeycode1161673').value;\n        if(keyword==null||keyword==\"\"){\n            alert(\"请输入你要检索的内容！\");\n            return false;\n        }\n        if(window.toFF==1)\n        {\n            document.getElementById(\"lucenenewssearchkey1161673\").value = Simplized(keyword );\n        }else\n        {\n            document.getElementById(\"lucenenewssearchkey1161673\").value = keyword;            \n        }\n        var  base64 = new Base64();\n        document.getElementById(\"lucenenewssearchkey1161673\").value = base64.encode(document.getElementById(\"lucenenewssearchkey1161673\").value);\n        new VsbFormFunc().disableAutoEnable(document.getElementById(\"showkeycode1161673\"));\n        return true;\n    } \n</script>\n<form action=\"../../ssjg.jsp?wbtreeid=1079\" method=\"post\" id=\"au14a\" name=\"au14a\" onsubmit=\"return _nl_ys_check()\" style=\"display: inline\">\n <input type=\"hidden\" id=\"lucenenewssearchkey1161673\" name=\"lucenenewssearchkey\" value=\"\"><input type=\"hidden\" id=\"_lucenesearchtype1161673\" name=\"_lucenesearchtype\" value=\"1\"><input type=\"hidden\" id=\"searchScope1161673\" name=\"searchScope\" value=\"0\">\n\n     <div class=\"input-group pore\">\n          <input type=\"text\" name=\"showkeycode\" id=\"showkeycode1161673\" class=\"inp\" placeholder=\"输入关键词搜索...\" autocomplete=\"off\">\n          <button class=\"sub\" type=\"submit\" align=\"absmiddle\" style=\"cursor: hand\"></button>\n     </div>\n \n</form><script language=\"javascript\" src=\"/system/resource/js/base64.js\"></script><script language=\"javascript\" src=\"/system/resource/js/formfunc.js\"></script>\n</div>\n    </div>\n\n<div class=\"hide\" id=\"gotop\">TOP</div>\n\n<script src=\"../../js/public.js\"></script>\n<script src=\"../../js/wave.js\"></script>\n<style>\n.n_pad1{ overflow: visible;}\n</style>\n\n\n\n</body></html>"
}